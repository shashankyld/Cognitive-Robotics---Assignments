{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .pbm file\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('Assignment_04_Grid_Map.png', cv2.IMREAD_GRAYSCALE)\n",
    "colour_img = cv2.imread('Assignment_04_Grid_Map.png', cv2.IMREAD_COLOR)\n",
    "# cv2.imshow('image', img)\n",
    "# cv2.waitKey(3000)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_model(pose, map):\n",
    "    n_rays = 180\n",
    "    angle_gap = 2\n",
    "\n",
    "    max_range = 12\n",
    "    measurements = {}\n",
    "    count = 0\n",
    "\n",
    "    for i in range(0, 2* n_rays, angle_gap):\n",
    "        direction = i-n_rays\n",
    "        print(\"outer :\", direction)\n",
    "        ray_angle = pose[2] + direction * np.pi / 180\n",
    "        x, y = pose[0], pose[1]\n",
    "        step1 =0.04/(np.cos(ray_angle))\n",
    "        step2 = 0.04/(np.sin(ray_angle))\n",
    "        step = min(step1, step2)\n",
    "        ray_occupancy_array = []\n",
    "        for distance in np.arange(0, max_range, step):\n",
    "            print(\"inside: \", direction)\n",
    "         \n",
    "            x_endpoint_pixel = round((x + distance * np.cos(ray_angle))/0.04)\n",
    "            y_endpoint_pixel = round((y + distance * np.sin(ray_angle))/0.04)\n",
    "            ray_occupancy_array.append([x_endpoint_pixel, y_endpoint_pixel])\n",
    "            if map[x_endpoint_pixel, y_endpoint_pixel] == 0:\n",
    "                #print(direction)\n",
    "                measurements[direction] = (distance, x_endpoint_pixel, y_endpoint_pixel, ray_occupancy_array)\n",
    "                break\n",
    "            #print(direction)\n",
    "            # measurements[direction] = (distance, x_endpoint_pixel, y_endpoint_pixel)\n",
    "    return measurements\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "robot_pose = [4, 5.4, 0]\n",
    "measurements = sensor_model(robot_pose, img)\n",
    "print(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OpenCV to visualize the robot pose and the measurements in colour_img\n",
    "\n",
    "cv2.circle(colour_img, (int(robot_pose[1]/0.04), int(robot_pose[0]/0.04)), 5, (0, 0, 255), -1)\n",
    "for key in measurements:\n",
    "    #cv2.line(colour_img, (int(robot_pose[1]/0.04), int(robot_pose[0]/0.04)), (measurements[key][2], measurements[key][1]), (0, 255, 0), 1)\n",
    "    # Visualize all steps of the ray\n",
    "    for step in measurements[key][3]:\n",
    "        # cv2.circle(colour_img, (step[1], step[0]), 1, (255, 0, 0), -1)\n",
    "        # Plot pixel instead of circle\n",
    "        colour_img[step[0], step[1]] = (255, 0, 0)\n",
    "\n",
    "cv2.imshow('image', colour_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
